{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xxZ4IHAiez1Z"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f4f5a1aecabf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IprNmp8ev1u",
    "outputId": "b6891757-48c6-4975-a1cd-5135c5785059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097, 477)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('movieReplicationSet.csv', delimiter = ',',skip_header = 1)\n",
    "p_value = []\n",
    "count = 0\n",
    "sum = 0\n",
    "a = np.empty((1097,477))\n",
    "for i in range(477):\n",
    "    temp = data[:,i:i+1]\n",
    "    temp2  = np.isfinite(data[:,i:i+1])\n",
    "    temp = temp[temp2]\n",
    "    avg = np.median(temp)\n",
    "    #print(avg)\n",
    "    for j in range(len(temp2)):\n",
    "        if temp2[j] == True:\n",
    "            a[j][i] = data[j,i]\n",
    "        else:\n",
    "            a[j][i] = avg\n",
    "a = np.abs(a.T) \n",
    "a.shape\n",
    "data=a.T\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "pmR6ndBbeV04"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class jani(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # TODO\n",
    "\n",
    "    self.fc1 = nn.Linear(77,200)\n",
    "\n",
    "    self.fc2 = nn.Linear(200,400)\n",
    "\n",
    "    self.fc3 = nn.Linear(400,600)\n",
    "\n",
    "    self.fc4=nn.Linear(600,400)\n",
    "    \n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.sig=nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # TODO\n",
    "    out=self.relu(self.fc1(x))\n",
    "    out=self.dropout(out)\n",
    "    out=self.fc2(out)\n",
    "    out=self.relu(out)\n",
    "    # out=self.dropout(out)\n",
    "    out=self.relu(self.fc3(out))\n",
    "    out=self.dropout(out)\n",
    "    out=self.relu(self.fc4(out))\n",
    "    return out\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWzsyEeafqgL",
    "outputId": "1c4a9e33-9848-433a-8ad2-ab625882a26b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(data, [1000, 97])\n",
    "train_data_loader=torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True, num_workers=4)\n",
    "test_data_loader=torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tInUzZzhdKU",
    "outputId": "c83ea667-1048-49cf-cc36-b6da4467b0a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([1, 400])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "model=jani()\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.parameters(),lr=0.0001)\n",
    "\n",
    "for val in train_data:\n",
    "  input=torch.tensor(val[400:]).float()\n",
    "  labels=torch.tensor(val[:400]).float()\n",
    "  labels=torch.round(labels)\n",
    "  pred=model(input)\n",
    "  # pred=torch.round(pred)\n",
    "  pred=pred.unsqueeze(0)\n",
    "  lables=labels.unsqueeze(0).unsqueeze(0)\n",
    "  # pred=torch.round(pred.unsqueeze(0))\n",
    "  # print('pred labels',pred[:10])\n",
    "  # print('true labels',labels[:10])\n",
    "  # print('pred labels',pred)\n",
    "  # print('true labels',labels)\n",
    "  optimizer.zero_grad()\n",
    "  # for i in range(len(pred)):\n",
    "  #   print(pred[0])\n",
    "  #   loss+=criterion(pred[i].unsqueeze(0),labels[i].unsqueeze(0))\n",
    "  loss=criterion(pred,labels)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAfqZp6XtLQH",
    "outputId": "5c99aca8-6945-498c-ab07-2c132c9755d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:- tensor(0.6686)\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "count=0\n",
    "acc=[]\n",
    "for val in test_data:\n",
    "  count=0\n",
    "  input=torch.tensor(val[400:]).float()\n",
    "  labels=torch.tensor(val[:400]).float().unsqueeze(0)\n",
    "  pred=model(input)\n",
    "  pred=torch.round(pred)\n",
    "  labels=torch.round(labels)\n",
    "  diff=pred-labels\n",
    "  count=400-torch.count_nonzero(diff)\n",
    "  # acc=count/400\n",
    "  acc.append(count/400)\n",
    "  # print(count/400)\n",
    "acc=torch.tensor(acc)\n",
    "print('accuracy is:-',torch.mean(acc))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "jani.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
